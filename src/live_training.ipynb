{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time EMG to Angle Prediction with TensorFlow and LSL\n",
    "\n",
    "This notebook demonstrates a more modular and robust approach to:\n",
    "- Collecting real-time EMG (EXG) and angle (FingerPercentages) data from LSL streams.\n",
    "- Applying online standardization to the EMG signals.\n",
    "- Using a configurable CNN model to predict angles from recent EMG data.\n",
    "\n",
    "**Features:**\n",
    "- Adjustable EMG window size for the CNN input.\n",
    "- More modular code structure with classes and separate functions.\n",
    "- Graceful handling of missing or invalid data.\n",
    "- Training on the most recent data available.\n",
    "\n",
    "**Notes:**\n",
    "- This example still assumes that LSL streams `filtered_exg` and `FingerPercentages` are available.\n",
    "- Ensure you have the required dependencies installed: `pylsl`, `tensorflow`, `numpy`.\n",
    "- Running this in real-time requires live LSL streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import threading\n",
    "import tensorflow as tf\n",
    "from pylsl import StreamInlet, resolve_stream, proc_ALL\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Standardizer\n",
    "This class maintains a running mean and std using Welford's algorithm, allowing for online standardization of incoming data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineStandardizer:\n",
    "    \"\"\"\n",
    "    Maintains a running mean and std using Welford's algorithm.\n",
    "    \"\"\"\n",
    "    def __init__(self, epsilon=1e-7):\n",
    "        self.count = 0\n",
    "        self.mean = 0.0\n",
    "        self.M2 = 0.0\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def copy(self):\n",
    "        new = OnlineStandardizer(self.epsilon)\n",
    "        new.count = self.count\n",
    "        new.mean = self.mean\n",
    "        new.M2 = self.M2\n",
    "        return new\n",
    "\n",
    "    def update(self, x: np.ndarray):\n",
    "        batch_count = x.shape[0]\n",
    "        \n",
    "        if batch_count == 0:\n",
    "            return\n",
    "\n",
    "        new_count = self.count + batch_count\n",
    "        \n",
    "        delta = x - self.mean\n",
    "        self.mean += np.sum(delta, axis=0) / new_count\n",
    "        delta2 = x - self.mean\n",
    "        self.M2 += np.sum(delta * delta2, axis=0)\n",
    "        self.count = new_count\n",
    "\n",
    "    def get_stats(self):\n",
    "        if self.count < 2:\n",
    "            return self.mean, np.ones_like(self.mean)\n",
    "        var = self.M2 / (self.count - 1)\n",
    "        std = np.sqrt(var)\n",
    "        std[std < self.epsilon] = self.epsilon\n",
    "        return self.mean, std\n",
    "\n",
    "    def apply(self, x: np.ndarray):\n",
    "        mean, std = self.get_stats()\n",
    "        x = (x - mean) / std\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMG-Angle Collector\n",
    "This class:\n",
    "- Connects to specified LSL streams for EMG and angles.\n",
    "- Continuously collects data in a background thread.\n",
    "- Maintains a buffer of recent data.\n",
    "- Rectifies EMG Signals and Applies Thresholds to Angles\n",
    "- Provides a method to extract the most recent data window for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyBuffer:\n",
    "    def __init__(self, capacity, shape, dtype):\n",
    "        self.capacity = capacity\n",
    "        self.shape = shape\n",
    "        self.dtype = dtype\n",
    "        self.buffer = np.zeros((capacity, *shape), dtype=dtype)\n",
    "        self.timestamps = np.zeros(capacity, dtype=np.float64)\n",
    "        self.size = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Adjust to work with negative indices and slices\n",
    "        def adjust_index(idx, limit=self.size):\n",
    "            if idx < 0:\n",
    "                idx += self.size\n",
    "            if idx < 0 or idx >= limit:\n",
    "                raise IndexError(\"Index out of bounds.\")\n",
    "            return idx\n",
    "        \n",
    "        if isinstance(idx, int):\n",
    "            idx = adjust_index(idx)\n",
    "            return self.timestamps[idx], self.buffer[idx]\n",
    "        elif isinstance(idx, slice):\n",
    "            start, stop, step = idx.indices(self.size)\n",
    "            start = adjust_index(start)\n",
    "            stop = adjust_index(stop, self.size + 1)\n",
    "            timestamps = self.timestamps[start:stop:step]\n",
    "            buffer = self.buffer[start:stop:step]\n",
    "            return timestamps, buffer\n",
    "        else:\n",
    "            raise TypeError(\"Invalid index type.\")\n",
    "        \n",
    "    def expand(self):\n",
    "        new_buffer = np.zeros((self.capacity * 2, *self.shape), dtype=self.dtype)\n",
    "        new_timestamps = np.zeros(self.capacity * 2, dtype=np.float64)\n",
    "        new_buffer[:self.size] = self.buffer\n",
    "        new_timestamps[:self.size] = self.timestamps\n",
    "        self.buffer = new_buffer\n",
    "        self.timestamps = new_timestamps\n",
    "        self.capacity *= 2\n",
    "    \n",
    "    def extend(self, timestamps, samples):\n",
    "        if len(timestamps) != len(samples):\n",
    "            raise ValueError(\"Timestamps and samples must have the same length.\")\n",
    "        \n",
    "        new_size = len(samples)\n",
    "        \n",
    "        if new_size == 0:\n",
    "            return\n",
    "        \n",
    "        if self.size + new_size > self.capacity:\n",
    "            self.expand()\n",
    "\n",
    "        self.buffer[self.size:self.size+new_size] = samples\n",
    "        self.timestamps[self.size:self.size+new_size] = timestamps\n",
    "        self.size += new_size\n",
    "\n",
    "    def get_numpy_buffers(self):\n",
    "        return self.timestamps[:self.size], self.buffer[:self.size]\n",
    "\n",
    "    def clear(self):\n",
    "        self.size = 0\n",
    "\n",
    "class EMGAngleCollector:\n",
    "    def __init__(self, emg_stream_name=\"filtered_exg\", angle_stream_name=\"FingerPercentages\",\n",
    "                 buffer_seconds=5, finger_thresholds = ((0.825, 0.9), (0.7, 0.875), (0.75, 0.875), (0.7, 0.8), (0.7, 0.825))):\n",
    "        print(\"Resolving EMG (EXG) stream...\")\n",
    "        emg_streams = resolve_stream('name', emg_stream_name)\n",
    "        if not emg_streams:\n",
    "            raise RuntimeError(f\"No EMG stream found with name '{emg_stream_name}'.\")\n",
    "        \n",
    "        print(\"Resolving angle (MP) stream...\")\n",
    "        angle_streams = resolve_stream('name', angle_stream_name)\n",
    "        if not angle_streams:\n",
    "            raise RuntimeError(f\"No angle stream found with name '{angle_stream_name}'.\")\n",
    "\n",
    "        self.emg_inlet = StreamInlet(emg_streams[0], processing_flags=proc_ALL, max_buflen=2)\n",
    "        self.angle_inlet = StreamInlet(angle_streams[0], processing_flags=proc_ALL, max_buflen=2)\n",
    "        self.finger_thresholds = np.array(finger_thresholds)\n",
    "\n",
    "        # Get EMG stream info\n",
    "        emg_info = self.emg_inlet.info()\n",
    "        self.emg_rate = emg_info.nominal_srate()\n",
    "        if self.emg_rate <= 0:\n",
    "            raise ValueError(\"EMG stream sampling rate is not set or zero.\")\n",
    "        self.num_exg_channels = emg_info.channel_count()\n",
    "        if self.num_exg_channels <= 0:\n",
    "            raise ValueError(\"EMG stream channel_count is not set or zero.\")\n",
    "\n",
    "        # Get angle stream info\n",
    "        angle_info = self.angle_inlet.info()\n",
    "        self.angle_rate = angle_info.nominal_srate()\n",
    "        if self.angle_rate <= 0:\n",
    "            raise ValueError(\"Angle stream sampling rate is not set or zero.\")\n",
    "        self.num_mp_channels = angle_info.channel_count()\n",
    "        if self.num_mp_channels <= 0:\n",
    "            raise ValueError(\"Angle stream channel_count is not set or zero.\")\n",
    "\n",
    "        self.capacity = int(buffer_seconds * self.emg_rate)\n",
    "\n",
    "        # Deques to store EMG and angle data\n",
    "        self.emg_deque = deque(maxlen=self.capacity)\n",
    "        self.emg_timestamp_deque = deque(maxlen=self.capacity)\n",
    "        self.angle_deque = deque(maxlen=self.capacity)\n",
    "        self.angle_timestamp_deque = deque(maxlen=self.capacity)\n",
    "        \n",
    "        # Standardizer for EMG data\n",
    "        self.standardizer = OnlineStandardizer()\n",
    "\n",
    "        self.data_lock = threading.Lock()\n",
    "        self.stop_flag = False\n",
    "        \n",
    "        self.update_fps = 50\n",
    "        self.update_interval = 1 / self.update_fps\n",
    "\n",
    "        self.thread = threading.Thread(target=self.run, daemon=True)\n",
    "        self.thread.start()\n",
    "\n",
    "    def run(self):\n",
    "        last_time = time.perf_counter()\n",
    "        while not self.stop_flag:\n",
    "            self.update()\n",
    "            current_time = time.perf_counter()\n",
    "            elapsed_time = current_time - last_time\n",
    "            if elapsed_time < self.update_interval:\n",
    "                time.sleep(self.update_interval - elapsed_time)\n",
    "            last_time = current_time\n",
    "    \n",
    "    def get_emg_standardizer(self):\n",
    "        with self.data_lock:\n",
    "            return self.standardizer.copy()\n",
    "\n",
    "    def update(self):\n",
    "        angle_data, angle_timestamps = self.angle_inlet.pull_chunk()\n",
    "        emg_data, emg_timestamps = self.emg_inlet.pull_chunk()\n",
    "\n",
    "        if not emg_data or not angle_data:\n",
    "            return\n",
    "\n",
    "        # Convert to arrays\n",
    "        emg_data = np.array(emg_data, dtype=np.float32)\n",
    "        angle_data = np.array(angle_data, dtype=np.float32)\n",
    "        \n",
    "        # Now create nan_mask safely - For now we won't remove any data\n",
    "        # emg_nan_mask = np.isnan(emg_data).any(axis=1)\n",
    "        # angle_nan_mask = np.isnan(angle_data).any(axis=1)\n",
    "        # emg_data = emg_data[~emg_nan_mask]\n",
    "        # angle_data = angle_data[~angle_nan_mask]\n",
    "        # emg_timestamps = np.array(emg_timestamps)[~emg_nan_mask]\n",
    "        # angle_timestamps = np.array(angle_timestamps)[~angle_nan_mask]\n",
    "        \n",
    "        # Rectify EMG data\n",
    "        emg_data = np.abs(emg_data)\n",
    "        \n",
    "        # Clip the angle data to the thresholds\n",
    "        angle_data = np.clip(angle_data, self.finger_thresholds[:, 0], self.finger_thresholds[:, 1])\n",
    "        angle_data = (angle_data - self.finger_thresholds[:, 0]) / (self.finger_thresholds[:, 1] - self.finger_thresholds[:, 0])\n",
    "        \n",
    "        with self.data_lock:\n",
    "            if len(emg_data) != 0:\n",
    "                self.emg_deque.extend(emg_data)\n",
    "                self.emg_timestamp_deque.extend(emg_timestamps)\n",
    "                self.standardizer.update(emg_data)\n",
    "            if len(angle_data) != 0:\n",
    "                self.angle_deque.extend(angle_data)\n",
    "                self.angle_timestamp_deque.extend(angle_timestamps)\n",
    "                \n",
    "    def get_data(self):\n",
    "        '''\n",
    "        Returns the EMG and angle data in the deques as numpy\n",
    "        arrays, and the standardizer object.\n",
    "        '''\n",
    "        with self.data_lock:\n",
    "            emg = np.array(self.emg_deque)\n",
    "            emg_timestamp = np.array(self.emg_timestamp_deque)\n",
    "            angle = np.array(self.angle_deque)\n",
    "            angle_timestamp = np.array(self.angle_timestamp_deque)\n",
    "            self.emg_deque.clear()\n",
    "            self.emg_timestamp_deque.clear()\n",
    "            self.angle_deque.clear()\n",
    "            self.angle_timestamp_deque.clear()\n",
    "            standardizer = self.standardizer.copy()\n",
    "        return (emg_timestamp, emg), (angle_timestamp, angle), standardizer\n",
    "                \n",
    "    def put_numpy_buffers(self, emg_buffer: NumpyBuffer, angle_buffer: NumpyBuffer):\n",
    "        timestamped_emg, timestamped_angle = self.get_data()\n",
    "        emg_buffer.extend(timestamped_emg[0], timestamped_emg[1])\n",
    "        angle_buffer.extend(timestamped_angle[0], timestamped_angle[1])\n",
    "    \n",
    "    def stop(self):\n",
    "        self.stop_flag = True\n",
    "        self.thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "\n",
    "This generator yields batches of data to the model for training. It:\n",
    "- Continuously calls `get_latest_batch` to get the most recent window.\n",
    "- Checks for NaNs or Infs.\n",
    "- Adds a batch dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(collector: EMGAngleCollector, batch_size:int, window_size: int, exg_buffer: NumpyBuffer, mp_buffer: NumpyBuffer):   \n",
    "    while True:\n",
    "        timestamped_exg, timestamped_mp, standardizer = collector.get_data()\n",
    "        \n",
    "        # Put the data in the buffers\n",
    "        exg_buffer.extend(timestamped_exg[0], timestamped_exg[1])\n",
    "        mp_buffer.extend(timestamped_mp[0], timestamped_mp[1])\n",
    "        \n",
    "        # Grab the earlier timestamp\n",
    "        exg_timestamps, exg_data = exg_buffer.get_numpy_buffers()\n",
    "        mp_timestamps, mp_data = mp_buffer.get_numpy_buffers()\n",
    "        \n",
    "        # Standardize the emg data\n",
    "        exg_data = standardizer.apply(exg_data)\n",
    "        \n",
    "        mp_idx = -1\n",
    "        exg_idx = -1\n",
    "        \n",
    "        # These 2 while loops are to ensure that the timestamps are aligned\n",
    "        # With the mp data ahead of the exg data\n",
    "        if len(mp_timestamps) == 0 or len(exg_timestamps) == 0:\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "        \n",
    "        while mp_idx > -len(mp_timestamps) and mp_timestamps[mp_idx] > exg_timestamps[exg_idx]:\n",
    "            mp_idx -= 1\n",
    "        # mp data should be ahead of exg data\n",
    "        while exg_idx > -len(exg_timestamps) and mp_timestamps[mp_idx] < exg_timestamps[exg_idx]:\n",
    "            exg_idx -= 1\n",
    "            \n",
    "        # Ensure indices are within bounds\n",
    "        if abs(mp_idx) > len(mp_timestamps) or abs(exg_idx) > len(exg_timestamps):\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "        \n",
    "        # Create a windowed dataset\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        for _ in range(batch_size):\n",
    "            if (exg_idx - window_size) < -len(exg_data):\n",
    "                break  # Not enough data for another sample\n",
    "            \n",
    "            # check for nan values in mp\n",
    "            while mp_idx > -len(mp_data) and np.isnan(mp_data[mp_idx]).any():\n",
    "                mp_idx -= 1\n",
    "                exg_idx -= 1\n",
    "            \n",
    "            if mp_idx < -len(mp_data):\n",
    "                break # Not enough data for another sample\n",
    "            \n",
    "            if (exg_idx - window_size) < -len(exg_data):\n",
    "                break  # Not enough data for another sample\n",
    "            \n",
    "            # Get the window of data\n",
    "            exg_window = exg_data[exg_idx - window_size:exg_idx]\n",
    "            mp_window = mp_data[mp_idx]\n",
    "            \n",
    "            # Append to the batch\n",
    "            X_batch.append(exg_window)\n",
    "            y_batch.append(mp_window)\n",
    "            \n",
    "            # Move the index\n",
    "            exg_idx -= 1\n",
    "            mp_idx -= 1\n",
    "            \n",
    "        if len(X_batch) == 0:\n",
    "            continue\n",
    "        \n",
    "        X_batch = np.array(X_batch, dtype=np.float32)  # (batch_size, window_size, num_exg_channels)\n",
    "        y_batch = np.array(y_batch, dtype=np.float32)  # (batch_size, num_mp_channels)\n",
    "        \n",
    "        # # print the distribution of the target\n",
    "        print('Mean', np.mean(y_batch, axis=0))\n",
    "        # print('STD', np.std(y_batch, axis=0))\n",
    "\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "A simple CNN model for sequence data. The kernel size and number of filters can be adjusted.\n",
    "\n",
    "We make the model creation more modular to easily tweak hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, num_exg_channels, num_mp_channels, filters=32, kernel_size=3):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(sequence_length, num_exg_channels)),\n",
    "        tf.keras.layers.GaussianNoise(0.05),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=filters*2, kernel_size=kernel_size, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=filters*2, kernel_size=kernel_size, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        # Output one value per MP channel\n",
    "        tf.keras.layers.Dense(num_mp_channels)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Here we:\n",
    "- Initialize the collector with chosen parameters.\n",
    "- Determine the sequence_length (window_size) from user input.\n",
    "- Create a `tf.data.Dataset` from the data generator.\n",
    "- Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving EMG (EXG) stream...\n",
      "Resolving angle (MP) stream...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'lo0' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'lo0' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:102   INFO| \tIPv4 addr: 7f000001\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'lo0' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:105   INFO| \tIPv6 addr: ::1\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'lo0' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::1%lo0\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'gif0' (status: 0, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'stf0' (status: 0, multicast: 0, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'anpi2' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'anpi1' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'anpi0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'en4' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'en5' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'en6' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'en1' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'en2' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'en3' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'bridge0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'utun0' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'utun0' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::6550:738c:b1b4:db3%utun0\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'ap1' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'en0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'en0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::1831:40cc:d67c:e762%en0\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'en0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:105   INFO| \tIPv6 addr: 2600:1700:71:3e70:1037:beb0:ff64:510c\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'en0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:105   INFO| \tIPv6 addr: 2600:1700:71:3e70:f2:dfca:6329:58f7\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'en0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:105   INFO| \tIPv6 addr: 2600:1700:71:3e70::34\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'en0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:102   INFO| \tIPv4 addr: c0a8018d\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'awdl0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'awdl0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::78ba:cfff:fe67:5895%awdl0\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'llw0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'llw0' (status: 1, multicast: 32768, broadcast: 2)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::78ba:cfff:fe67:5895%llw0\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'utun1' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'utun1' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::5591:cffc:9856:a3aa%utun1\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'utun2' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.049s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'utun2' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.050s) [          194FDC]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::e811:2bac:5492:eddb%utun2\n",
      "2024-12-13 02:16:38.947 (   0.050s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'utun3' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.050s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'utun3' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.050s) [          194FDC]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::ce81:b1c:bd2c:69e%utun3\n",
      "2024-12-13 02:16:38.947 (   0.050s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'utun4' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.050s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'utun4' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.050s) [          194FDC]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::4931:3362:2354:4ce0%utun4\n",
      "2024-12-13 02:16:38.947 (   0.050s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'utun5' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.050s) [          194FDC]      netinterfaces.cpp:91    INFO| netif 'utun5' (status: 1, multicast: 32768, broadcast: 0)\n",
      "2024-12-13 02:16:38.947 (   0.050s) [          194FDC]      netinterfaces.cpp:105   INFO| \tIPv6 addr: fe80::ead7:cf2a:42a1:e707%utun5\n",
      "2024-12-13 02:16:38.947 (   0.050s) [          194FDC]         api_config.cpp:271   INFO| Loaded default config\n",
      "2024-12-13 02:16:38.950 (   0.053s) [          194FDC]             common.cpp:66    INFO| git:v1.16.2-34-g7e61a2ef/branch:master/build:Release/compiler:AppleClang-15.0.0.15000309/link:SHARED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training loop. Press Interrupt to stop.\n",
      "Epoch 1/1000\n",
      "Mean [1. 1. 1. 1. 1.]\n",
      "Mean [1. 1. 1. 1. 1.]\n",
      "Stopped data collection and training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 02:16:44.945596: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\n",
      "\n",
      "\n",
      "2024-12-13 02:16:44.945657: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]]\n",
      "2024-12-13 02:16:44.949114: W tensorflow/core/framework/op_kernel.cc:1827] INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\n",
      "\n",
      "\n",
      "2024-12-13 02:16:44.968742: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: TypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]]\n",
      "\t [[StatefulPartitionedCall/sequential_1/gaussian_noise_1/stateless_random_normal/StatelessRandomGetKeyCounter/_64]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  TypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\nTraceback (most recent call last):\n\n  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[StatefulPartitionedCall/sequential_1/gaussian_noise_1/stateless_random_normal/StatelessRandomGetKeyCounter/_64]]\n  (1) INVALID_ARGUMENT:  TypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\nTraceback (most recent call last):\n\n  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_one_step_on_iterator_2342]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training loop. Press Interrupt to stop.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEPS_PER_EPOCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining interrupted by user.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  TypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\nTraceback (most recent call last):\n\n  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[StatefulPartitionedCall/sequential_1/gaussian_noise_1/stateless_random_normal/StatelessRandomGetKeyCounter/_64]]\n  (1) INVALID_ARGUMENT:  TypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\nTraceback (most recent call last):\n\n  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/Users/sj/Dev/Python/robot-hand/.conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 235, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element of shape (912, 50, 16) where an element of shape (1024, 50, 16) was expected.\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_one_step_on_iterator_2342]"
     ]
    }
   ],
   "source": [
    "# User-configurable parameters\n",
    "EMG_STREAM_NAME = \"filtered_exg\"\n",
    "ANGLE_STREAM_NAME = \"FingerPercentages\"\n",
    "COLLECTOR_BUFFER_SECONDS = 5\n",
    "EXPECTED_SESSION_SECONDS = 60 * 10\n",
    "WINDOW_SIZE = 50  # Number of EMG samples per example\n",
    "BATCH_SIZE = 1024 # Examples per training step\n",
    "STEPS_PER_EPOCH = 10\n",
    "EPOCHS = 1000\n",
    "FILTERS = 32\n",
    "KERNEL_SIZE = 3\n",
    "\n",
    "# Initialize collector\n",
    "collector = EMGAngleCollector(\n",
    "    emg_stream_name=EMG_STREAM_NAME,\n",
    "    angle_stream_name=ANGLE_STREAM_NAME,\n",
    "    buffer_seconds=COLLECTOR_BUFFER_SECONDS,\n",
    ")\n",
    "\n",
    "# Initialize buffers\n",
    "exg_buffer = NumpyBuffer(int(collector.emg_rate * EXPECTED_SESSION_SECONDS), (collector.num_exg_channels,), np.float32)\n",
    "mp_buffer = NumpyBuffer(int(collector.angle_rate * EXPECTED_SESSION_SECONDS), (collector.num_mp_channels,), np.float32)\n",
    "\n",
    "num_exg_channels = collector.num_exg_channels\n",
    "num_mp_channels = collector.num_mp_channels\n",
    "\n",
    "# Create dataset\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(collector, window_size=WINDOW_SIZE, batch_size=BATCH_SIZE, exg_buffer=exg_buffer, mp_buffer=mp_buffer),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(BATCH_SIZE, WINDOW_SIZE, num_exg_channels), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(BATCH_SIZE, num_mp_channels), dtype=tf.float32)\n",
    "    ),\n",
    "    drop_remainder=True\n",
    ").prefetch(1)\n",
    "\n",
    "# Create model\n",
    "model = create_model(WINDOW_SIZE, num_exg_channels, num_mp_channels, filters=FILTERS, kernel_size=KERNEL_SIZE)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "print(\"Starting training loop. Press Interrupt to stop.\")\n",
    "try:\n",
    "    model.fit(dataset, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted by user.\")\n",
    "finally:\n",
    "    collector.stop()\n",
    "    print(\"Stopped data collection and training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
